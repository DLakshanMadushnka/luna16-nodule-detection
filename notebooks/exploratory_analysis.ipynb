{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis: LUNA16 Lung Nodule Detection\n",
        "\n",
        "This notebook performs an initial exploration of the LUNA16 dataset, focusing on CT scan visualization, nodule distribution, and patch sampling. It assumes access to the dataset files (annotations.csv, candidates.csv, and .mhd scans) mounted via Google Drive or locally.\n",
        "\n",
        "## Setup\n",
        "- Mount Google Drive if using Colab.\n",
        "- Install required libraries."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Install dependencies (run once)\n",
        "!pip install SimpleITK pandas numpy matplotlib seaborn scikit-learn opencv-python\n",
        "\n",
        "# Imports\n",
        "import SimpleITK as sitk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from glob import glob\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "\n",
        "# Mount Drive (Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Paths\n",
        "DATA_PATH = '/content/drive/MyDrive/LUNA16/'\n",
        "ANNOTATIONS_FILE = os.path.join(DATA_PATH, 'annotations.csv')\n",
        "CANDIDATES_FILE = os.path.join(DATA_PATH, 'candidates.csv')\n",
        "\n",
        "print('Setup complete.')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load and Inspect Metadata\n",
        "\n",
        "Examine the annotations (nodules) and candidates (potential nodules) CSV files."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Load CSVs\n",
        "annotations = pd.read_csv(ANNOTATIONS_FILE)\n",
        "candidates = pd.read_csv(CANDIDATES_FILE)\n",
        "\n",
        "print('Annotations (Nodules):')\n",
        "print(annotations.head())\n",
        "print(f'Shape: {annotations.shape}')\n",
        "\n",
        "print('\\nCandidates:')\n",
        "print(candidates.head())\n",
        "print(f'Shape: {candidates.shape}')\n",
        "\n",
        "# Class distribution in candidates\n",
        "class_dist = candidates['class'].value_counts().sort_index()\n",
        "print(f'\\nClass Distribution:\\n{class_dist}')\n",
        "\n",
        "# Plot distribution\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.barplot(x=class_dist.index, y=class_dist.values)\n",
        "plt.title('Distribution of Candidates (0: Non-Nodule, 1: Nodule)')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load a Sample CT Scan\n",
        "\n",
        "Load and visualize a single .mhd file to understand the 3D structure."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def load_sample_scan(seriesuid):\n",
        "    mhd_files = glob(os.path.join(DATA_PATH, 'subset*/', f'{seriesuid}.mhd'))\n",
        "    if not mhd_files:\n",
        "        raise ValueError(f'No .mhd file found for {seriesuid}')\n",
        "    \n",
        "    itkimage = sitk.ReadImage(mhd_files[0])\n",
        "    ct_scan = sitk.GetArrayFromImage(itkimage)  # Shape: (slices, height, width)\n",
        "    \n",
        "    # Convert to Hounsfield (simple shift for visualization)\n",
        "    ct_scan = ct_scan.astype(np.float32) - 1024\n",
        "    \n",
        "    return ct_scan\n",
        "\n",
        "# Sample seriesuid (from annotations)\n",
        "sample_seriesuid = annotations['seriesuid'].iloc[0]\n",
        "print(f'Loading sample scan: {sample_seriesuid}')\n",
        "ct_scan = load_sample_scan(sample_seriesuid)\n",
        "print(f'Scan shape: {ct_scan.shape}')\n",
        "print(f'Value range: [{ct_scan.min():.1f}, {ct_scan.max():.1f}] HU')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Visualize middle slices\n",
        "fig, axes = plt.subplots(1, 10, figsize=(20, 4))\n",
        "mid_slice = ct_scan.shape[0] // 2\n",
        "start = max(0, mid_slice - 4)\n",
        "end = min(ct_scan.shape[0], mid_slice + 5)\n",
        "\n",
        "for i, z in enumerate(range(start, end)):\n",
        "    axes[i].imshow(ct_scan[z], cmap='gray', vmin=-1000, vmax=400)\n",
        "    axes[i].set_title(f'Slice {z}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle('Sample CT Slices (Axial View)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Visualize Nodule Locations\n",
        "\n",
        "Overlay nodule coordinates on a sample slice for context."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def world_to_voxel_coords(coords, origin, spacing):\n",
        "    voxel_coords = np.round((coords - origin) / spacing).astype(int)\n",
        "    return voxel_coords\n",
        "\n",
        "# Load metadata for sample scan\n",
        "itkimage = sitk.ReadImage(glob(os.path.join(DATA_PATH, 'subset*/', f'{sample_seriesuid}.mhd'))[0])\n",
        "origin = np.array(itkimage.GetOrigin())\n",
        "spacing = np.array(itkimage.GetSpacing())\n",
        "\n",
        "# Get nodules for this scan\n",
        "sample_nodules = annotations[annotations['seriesuid'] == sample_seriesuid]\n",
        "print(f'Nodules in sample scan: {len(sample_nodules)}')\n",
        "\n",
        "# Plot middle slice with nodule markers\n",
        "mid_slice = ct_scan.shape[0] // 2\n",
        "slice_img = ct_scan[mid_slice]\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
        "ax.imshow(slice_img, cmap='gray', vmin=-1000, vmax=400)\n",
        "\n",
        "# Mark nodule positions (project to this slice if nearby)\n",
        "for _, nodule in sample_nodules.iterrows():\n",
        "    coords = np.array([nodule['coordX'], nodule['coordY'], nodule['coordZ']])\n",
        "    voxel = world_to_voxel_coords(coords, origin, spacing)\n",
        "    if abs(voxel[0] - mid_slice) < 5:  # Nearby slices\n",
        "        ax.plot(voxel[1], voxel[2], 'r+', markersize=10, markeredgewidth=2)\n",
        "\n",
        "ax.set_title(f'Middle Slice with Nodule Markers (Red +)')\n",
        "ax.axis('off')\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Sample Patch Extraction\n",
        "\n",
        "Extract and visualize sample patches around a nodule and a non-nodule."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def extract_patch(ct_scan, coords, origin, spacing, patch_size=64):\n",
        "    voxel = world_to_voxel_coords(coords, origin, spacing)\n",
        "    z, y, x = voxel\n",
        "    z = np.clip(z, 0, ct_scan.shape[0] - 1)\n",
        "    half = patch_size // 2\n",
        "    y_start = np.clip(y - half, 0, ct_scan.shape[1])\n",
        "    y_end = np.clip(y + half, 0, ct_scan.shape[1])\n",
        "    x_start = np.clip(x - half, 0, ct_scan.shape[2])\n",
        "    x_end = np.clip(x + half, 0, ct_scan.shape[2])\n",
        "    \n",
        "    patch = ct_scan[z, y_start:y_end, x_start:x_end]\n",
        "    # Resize if needed\n",
        "    if patch.shape != (patch_size, patch_size):\n",
        "        patch = cv2.resize(patch, (patch_size, patch_size), interpolation=cv2.INTER_LINEAR)\n",
        "    return patch\n",
        "\n",
        "# Sample nodule patch\n",
        "if len(sample_nodules) > 0:\n",
        "    nodule_row = sample_nodules.iloc[0]\n",
        "    nodule_coords = np.array([nodule_row['coordX'], nodule_row['coordY'], nodule_row['coordZ']])\n",
        "    nodule_patch = extract_patch(ct_scan, nodule_coords, origin, spacing)\n",
        "\n",
        "# Sample non-nodule from candidates\n",
        "non_nodule_candidates = candidates[(candidates['seriesuid'] == sample_seriesuid) & (candidates['class'] == 0)]\n",
        "if len(non_nodule_candidates) > 0:\n",
        "    non_nodule_row = non_nodule_candidates.iloc[0]\n",
        "    non_nodule_coords = np.array([non_nodule_row['coordX'], non_nodule_row['coordY'], non_nodule_row['coordZ']])\n",
        "    non_nodule_patch = extract_patch(ct_scan, non_nodule_coords, origin, spacing)\n",
        "\n",
        "# Visualize patches\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "if 'nodule_patch' in locals():\n",
        "    axes[0].imshow(nodule_patch, cmap='gray', vmin=-1000, vmax=400)\n",
        "    axes[0].set_title('Nodule Patch')\n",
        "    axes[0].axis('off')\n",
        "if 'non_nodule_patch' in locals():\n",
        "    axes[1].imshow(non_nodule_patch, cmap='gray', vmin=-1000, vmax=400)\n",
        "    axes[1].set_title('Non-Nodule Patch')\n",
        "    axes[1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Dataset Statistics\n",
        "\n",
        "Summary stats across scans."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Scans per subset\n",
        "subsets = glob(os.path.join(DATA_PATH, 'subset*'))\n",
        "scan_counts = {os.path.basename(s): len(glob(os.path.join(s, '*.mhd'))) for s in subsets}\n",
        "print('Scans per subset:')\n",
        "for k, v in scan_counts.items():\n",
        "    print(f'{k}: {v}')\n",
        "\n",
        "# Nodules per scan\n",
        "nodules_per_scan = annotations['seriesuid'].value_counts()\n",
        "print(f'\\nNodules per scan - Min: {nodules_per_scan.min()}, Max: {nodules_per_scan.max()}, Mean: {nodules_per_scan.mean():.1f}')\n",
        "\n",
        "# Plot nodules distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "nodules_per_scan.hist(bins=20)\n",
        "plt.title('Distribution of Nodules per Scan')\n",
        "plt.xlabel('Number of Nodules')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Balanced Sampling Preview\n",
        "\n",
        "Simulate balanced sampling for training."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "positive_count = len(annotations)\n",
        "negative_candidates = candidates[candidates['class'] == 0]\n",
        "balanced_negatives = negative_candidates.sample(n=positive_count, random_state=42)\n",
        "\n",
        "print(f'Original negatives: {len(negative_candidates)}')\n",
        "print(f'Balanced negatives: {len(balanced_negatives)}')\n",
        "print(f'Total balanced samples: {len(annotations) + len(balanced_negatives)}')\n",
        "\n",
        "# Split preview\n",
        "all_samples = pd.concat([annotations.assign(class=1)[['seriesuid', 'coordX', 'coordY', 'coordZ', 'class']], \n",
        "                         balanced_negatives[['seriesuid', 'coordX', 'coordY', 'coordZ', 'class']]], ignore_index=True)\n",
        "train_samples, test_samples = train_test_split(all_samples, test_size=0.2, random_state=42, stratify=all_samples['class'])\n",
        "\n",
        "print(f'\\nTrain: {len(train_samples)} samples ({np.sum(train_samples[\"class\"] == 1)} positives)')\n",
        "print(f'Test: {len(test_samples)} samples ({np.sum(test_samples[\"class\"] == 1)} positives)')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "This EDA reveals a highly imbalanced dataset (many more non-nodules), justifying balancing and augmentation. Scans show typical lung CT densities (-1000 to +400 HU). Nodules are sparse, emphasizing the need for precise patch extraction. Proceed to full preprocessing and modeling."
      ],
      "metadata": {}
    }
  ]
}
